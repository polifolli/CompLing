{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b20f786e",
   "metadata": {},
   "source": [
    "# Домашнее задание № 2. Мешок слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.metrics.pairwise import cosine_distances, cosine_similarity\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from razdel import tokenize as razdel_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf72d19",
   "metadata": {},
   "source": [
    "## Задание 1 (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a045e99",
   "metadata": {},
   "source": [
    "У векторайзеров в sklearn есть встроенная токенизация на регулярных выражениях. Найдите способо заменить её на кастомную токенизацию"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b4d453",
   "metadata": {},
   "source": [
    "Обучите векторайзер с дефолтной токенизацией и с токенизацией razdel.tokenize. Обучите классификатор (любой) с каждым из векторизаторов. Сравните метрики и выберете победителя. \n",
    "\n",
    "(в вашей тетрадке должен быть код обучения и все метрики; если вы сдаете в .py файлах то сохраните полученные метрики в отдельном файле или в комментариях)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4314de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('labeled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d2477b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.reset_index(inplace=True)\n",
    "test.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_default = TfidfVectorizer(min_df=10, max_df=0.3)\n",
    "X_default = vectorizer_default.fit_transform(train.comment)\n",
    "X_test_default = vectorizer_default.transform(test.comment) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_default = train.toxic.values\n",
    "y_test_default = test.toxic.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.86      0.84       954\n",
      "         1.0       0.70      0.64      0.67       488\n",
      "\n",
      "    accuracy                           0.78      1442\n",
      "   macro avg       0.76      0.75      0.75      1442\n",
      "weighted avg       0.78      0.78      0.78      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_default = KNeighborsClassifier(n_neighbors=10, metric='cosine')\n",
    "clf_default.fit(X_default, y_default)\n",
    "preds_default = clf_default.predict(X_test_default)\n",
    "\n",
    "print(classification_report(y_test_default, preds_default))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_tokenizer(text):\n",
    "    tokens = [token.text for token in list(razdel_tokenize(text))]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Home\\scoop\\apps\\python\\current\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "vectorizer_custom = TfidfVectorizer(tokenizer=r_tokenizer, min_df=10, max_df=0.3)\n",
    "X_custom = vectorizer_custom.fit_transform(train.comment)\n",
    "X_test_custom = vectorizer_custom.transform(test.comment) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_custom = train.toxic.values\n",
    "y_test_custom = test.toxic.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.83      0.83       954\n",
      "         1.0       0.67      0.65      0.66       488\n",
      "\n",
      "    accuracy                           0.77      1442\n",
      "   macro avg       0.74      0.74      0.74      1442\n",
      "weighted avg       0.77      0.77      0.77      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_custom = KNeighborsClassifier(n_neighbors=10, metric='cosine')\n",
    "clf_custom.fit(X_custom, y_custom)\n",
    "preds_custom = clf_custom.predict(X_test_custom)\n",
    "\n",
    "print(classification_report(y_test_custom, preds_custom))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Наблюдения\n",
    "Токенайзер из razdel показал хорошие результаты, но все таки они чуть хуже дефолтного токенайзера."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b9076e",
   "metadata": {},
   "source": [
    "## Задание 2 (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e25357",
   "metadata": {},
   "source": [
    "Обучите 2 любых разных классификатора из семинара. Предскажите токсичность для текстов из тестовой выборки (используйте одну и ту же выборку для обоих классификаторов) и найдите 10 самых токсичных для каждого из классификаторов. Сравните получаемые тексты - какие тексты совпадают, какие отличаются, правда ли тексты токсичные?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de962ad",
   "metadata": {},
   "source": [
    "Требования к моделям:   \n",
    "а) один классификатор должен использовать CountVectorizer, другой TfidfVectorizer  \n",
    "б) у векторазера должны быть вручную заданы как минимум 5 параметров (можно ставить разные параметры tfidfvectorizer и countvectorizer)  \n",
    "в) у классификатора должно быть задано вручную как минимум 2 параметра (по возможности)  \n",
    "г)  f1 мера каждого из классификаторов должна быть минимум 0.75  \n",
    "\n",
    "*random_seed не считается за параметр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Home\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac0a5471",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Home\\scoop\\apps\\python\\current\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.97      0.87       944\n",
      "         1.0       0.90      0.51      0.65       498\n",
      "\n",
      "    accuracy                           0.81      1442\n",
      "   macro avg       0.84      0.74      0.76      1442\n",
      "weighted avg       0.83      0.81      0.79      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=1, max_df=0.3, stop_words=stops, tokenizer = r_tokenizer, lowercase=True)\n",
    "X = vectorizer.fit_transform(train.comment)\n",
    "X_test = vectorizer.transform(test.comment) \n",
    "\n",
    "y = train.toxic.values\n",
    "y_test = test.toxic.values\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=10, n_jobs = 2, metric = 'cosine')\n",
    "clf.fit(X, y)\n",
    "preds = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[array(['хохол'], dtype='<U67')],\n",
       " [array(['татарин', 'пидарасы', 'мимо', 'астраханский'], dtype='<U67')],\n",
       " [array(['чмо', 'ха', 'лох', '!'], dtype='<U67')],\n",
       " [array(['хохлы'], dtype='<U67')],\n",
       " [array(['хохлов', 'забыл'], dtype='<U67')],\n",
       " [array(['свидетель', 'петух'], dtype='<U67')],\n",
       " [array(['прокладки', 'ебать', 'бомбит'], dtype='<U67')],\n",
       " [array(['чурка', 'тащемта', 'татарин', 'попали', 'леваки', 'дурак', 'геи'],\n",
       "        dtype='<U67')],\n",
       " [array(['шлюха', 'хуесос', 'пидорас', 'оп', 'мать', 'конченный', '-'],\n",
       "        dtype='<U67')],\n",
       " [array(['маски', 'лицо', 'жмет'], dtype='<U67')]]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percents_top10 = list(np.sort(clf.predict_proba(X_test)[:, 1])[::-1][:10])\n",
    "indices_top10  = list(np.argsort(clf.predict_proba(X_test)[:, 1])[::-1][:10])\n",
    "top10_sents = [vectorizer.inverse_transform(X_test[i]) for i in indices_top10]\n",
    "top10_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "745bd58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Home\\scoop\\apps\\python\\current\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.71      0.78       953\n",
      "         1.0       0.59      0.80      0.68       489\n",
      "\n",
      "    accuracy                           0.74      1442\n",
      "   macro avg       0.73      0.75      0.73      1442\n",
      "weighted avg       0.78      0.74      0.75      1442\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Home\\scoop\\apps\\python\\current\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(min_df=1, max_df=0.3, stop_words=stops, tokenizer = r_tokenizer, lowercase=True)\n",
    "X = vectorizer.fit_transform(train.comment)\n",
    "X_test = vectorizer.transform(test.comment) \n",
    "\n",
    "y = train.toxic.values\n",
    "y_test = test.toxic.values\n",
    "\n",
    "clf = LogisticRegression(C=0.1, penalty='elasticnet', class_weight='balanced', max_iter=100, solver='saga', l1_ratio = 0.5)\n",
    "clf.fit(X, y)\n",
    "preds = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90311fac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[array(['!', '-', ':', '?', 'баный', 'белых', 'бля', 'блядь', 'будем',\n",
       "         'вводит', 'вегетарианство', 'верит', 'вещи', 'вмешивается',\n",
       "         'вокруг', 'всем', 'вспомни', 'всё', 'выстрелить', 'говорю',\n",
       "         'головой', 'голубей', 'дальше', 'делал', 'дело', 'должен', 'друг',\n",
       "         'друга', 'дураком', 'ебучие', 'ем', 'ещё', 'жалко', 'жгли',\n",
       "         'животных', 'живьём', 'заботится', 'заботиться', 'заставляет',\n",
       "         'итог', 'картошка', 'картошку', 'которых', 'кошек', 'любить',\n",
       "         'люблю', 'люди', 'медленно', 'могу', 'можешь', 'мышей', 'мяса',\n",
       "         'мясо', 'начинают', 'неправильно', 'неё', 'объясняет', 'огонь',\n",
       "         'организм', 'остальные', 'отвечает', 'перевести', 'пизди',\n",
       "         'пиздёж', 'поддержать', 'подростковых', 'показывает', 'показывая',\n",
       "         'полному', 'полным', 'попытку', 'порыв', 'послать', 'поступает',\n",
       "         'почему', 'правильно', 'представляю', 'просто', 'равно', 'разные',\n",
       "         'самое', 'самые', 'свинью', 'своим', 'свой', 'сказал', 'слабее',\n",
       "         'смеются', 'смысла', 'собак', 'собаку', 'согласны', 'спорить',\n",
       "         'стреляли', 'съесть', 'такое', 'тебе', 'телом', 'терпеть', 'тех',\n",
       "         'типа', 'тобой', 'тошнит', 'трясётся', 'убить', 'ублюдки',\n",
       "         'угораю', 'узнала', 'хочется', 'хочешь', 'хуй', 'чувак', 'э',\n",
       "         'это'], dtype='<U67')],\n",
       " [array(['-', '?', 'абу', 'але', 'аноны', 'аутист', 'баны', 'больно',\n",
       "         'будут', 'быдло', 'взглядов', 'власти', 'внимание', 'возьмет',\n",
       "         'вообще', 'всем', 'встав', 'выглядит', 'выглядить', 'говна',\n",
       "         'гомиков', 'гомофорса', 'гомофорсе', 'давай', 'дал', 'две',\n",
       "         'доверять', 'должна', 'должны', 'доска', 'доске', 'доски', 'доску',\n",
       "         'других', 'дружок', 'забанены', 'залог', 'зарегулировать', 'игра',\n",
       "         'игру', 'избирательного', 'имеешь', 'иному', 'искусственно',\n",
       "         'какое-то', 'кусок', 'лево', 'лицо', 'лично', 'людей', 'люди',\n",
       "         'могут', 'надоели', 'намек', 'нахуя', 'начинаешь', 'неделю',\n",
       "         'некий', 'некоторые', 'несешь', 'никакой', 'ноги', 'нравится',\n",
       "         'обрати', 'общаются', 'общем', 'особо', 'открыто', 'относительно',\n",
       "         'отношению', 'отношения', 'отсутствие', 'охуел', 'пермач',\n",
       "         'пикабу', 'пили', 'по-другому', 'повторюсь', 'поехал', 'попасть',\n",
       "         'порядки', 'постинга', 'поэтому', 'правилам', 'право', 'принял',\n",
       "         'против', 'пытаясь', 'раздавать', 'раздела', 'решил', 'сайт',\n",
       "         'свое', 'своих', 'свой', 'системность', 'следования', 'снять',\n",
       "         'собственные', 'срач', 'средние', 'сроки', 'ссать', 'стабильного',\n",
       "         'стали', 'стесняешься', 'сука', 'считаю', 'таблеток', 'таким',\n",
       "         'такое', 'твоя', 'тебе', 'теме', 'той', 'тому', 'увидев',\n",
       "         'упорствующие', 'утра', 'фаворитизма', 'форс', 'форсу', 'честная',\n",
       "         'честной', 'чушок', 'шизофреник', 'это'], dtype='<U67')],\n",
       " [array(['!', '(', ')', '10', '?', 'аниме', 'блядь', 'вайпы', 'вебм',\n",
       "         'вебмки', 'вставляет', 'говно', 'говорю', 'голове', 'двощи',\n",
       "         'дебил', 'дебилу', 'десяток', 'должен', 'дрочить', 'ебаные',\n",
       "         'ебать', 'захотелось', 'зацени', 'звук', 'иди', 'интернет',\n",
       "         'использовать', 'каждый', 'каких', 'какой-то', 'клавиатуры',\n",
       "         'кому-то', 'могут', 'мышки', 'нарушают', 'нашелся', 'никакой',\n",
       "         'одному', 'остальные', 'ответ', 'пойми', 'понравился', 'пор',\n",
       "         'постов', 'постоянно', 'посты', 'похвастаться', 'почистить',\n",
       "         'проблемы', 'пропадает', 'просто', 'просят', 'пусть', 'решил',\n",
       "         'руки', 'свобода', 'свободу', 'своего', 'сделай', 'серьезно',\n",
       "         'скримеров', 'скрывают', 'создай', 'тебе', 'тише', 'тред', 'треда',\n",
       "         'треде', 'трогать', 'трут', 'удалить', 'умник', 'хочет', 'хуй',\n",
       "         'что-то', 'этим', 'это'], dtype='<U67')],\n",
       " [array(['?', 'жопу', 'кот', 'лицо', 'нюхает', 'подходит', 'почему',\n",
       "         'собака', 'суёт', 'твою', 'тебе'], dtype='<U67')],\n",
       " [array(['!', '?', 'алексея', 'блоки', 'бред', 'валера', 'вся', 'вчера',\n",
       "         'говна', 'дженерал', 'друзья', 'ебобо', 'ебу', 'защищает',\n",
       "         'знатно', 'золотов', 'инфо', 'историю', 'мимопроходил', 'мол',\n",
       "         'нахуй', 'одни', 'опустился', 'понты', 'понял', 'посмотрел',\n",
       "         'правильно', 'проиграл', 'сегодня', 'смотрю', 'тредик', 'уровень',\n",
       "         'хуя', 'че', 'чет', 'читал', 'это'], dtype='<U67')],\n",
       " [array(['-', '?', 'всеми', 'вывода', 'заместитель', 'кризиса', 'нужно',\n",
       "         'пиздуй', 'пиши', 'план', 'подпись', 'понятным', 'посмотрели',\n",
       "         'поставили', 'поставлю', 'проблему', 'работать', 'регион',\n",
       "         'региона', 'решить', 'таблицы', 'тебе', 'хана', 'цифра', 'че',\n",
       "         'чей', 'это', 'языком'], dtype='<U67')],\n",
       " [array(['-', '?', 'аборты', 'афроктототам', 'благородной', 'болеть',\n",
       "         'века', 'всеми', 'гаком', 'говно', 'гомосеком', 'горчичники',\n",
       "         'давай', 'дать', 'делами', 'денег', 'ебутся', 'ещё', 'женщины',\n",
       "         'захотел', 'имеют', 'иностранщину', 'кого', 'коклюшами', 'крутить',\n",
       "         'мужчины', 'мусьё', 'нам', 'наш', 'негры', 'опасно', 'остоебенело',\n",
       "         'переводят', 'подагры', 'подзалупную', 'подлизывать', 'пола',\n",
       "         'похуй', 'поэтому', 'прав', 'россии', 'скарлатинами', 'стыдно',\n",
       "         'такие', 'тарелки', 'тебе', 'умные', 'учиться', 'читать', 'это',\n",
       "         'язык'], dtype='<U67')],\n",
       " [array(['блять', 'других', 'дядя', 'иди', 'ой', 'свинья', 'своей',\n",
       "         'скажет', 'тебе'], dtype='<U67')],\n",
       " [array(['!', '-', 'азиатов', 'азиатские', 'белые', 'белых', 'девки',\n",
       "         'куколдаллеса', 'негров', 'план', 'понял', 'раскрылся', 'расовый',\n",
       "         'ч', 'это'], dtype='<U67')],\n",
       " [array(['!', ':', 'всё', 'вызвали', 'либерастня', 'небось', 'обычно',\n",
       "         'отрезать', 'призывы', 'репосты', 'хуи', 'хуйня', 'это'],\n",
       "        dtype='<U67')]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percents_top10 = list(np.sort(clf.predict_proba(X_test)[:, 1])[::-1][:10])\n",
    "indices_top10  = list(np.argsort(clf.predict_proba(X_test)[:, 1])[::-1][:10])\n",
    "top10_sents = [vectorizer.inverse_transform(X_test[i]) for i in indices_top10]\n",
    "top10_sents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f228c3e",
   "metadata": {},
   "source": [
    "## Задание 3 (4 балла - 1 балл за каждый классификатор)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566929b7",
   "metadata": {},
   "source": [
    "Для классификаторов Logistic Regression, Decision Trees, Naive Bayes, RandomForest найдите способ извлечь важность признаков для предсказания токсичного класса. Сопоставьте полученные числа со словами (или нграммами) в словаре и найдите топ - 5 \"токсичных\" слов для каждого из классификаторов. \n",
    "\n",
    "Важное требование: в топе не должно быть стоп-слов. Для этого вам нужно будет правильным образом настроить векторизацию. \n",
    "Также как и в предыдущем задании у классификаторов должно быть задано вручную как минимум 2 параметра (по возможности, f1 мера каждого из классификаторов должна быть минимум 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "81f86878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.70      0.79       953\n",
      "         1.0       0.60      0.87      0.71       489\n",
      "\n",
      "    accuracy                           0.76      1442\n",
      "   macro avg       0.75      0.78      0.75      1442\n",
      "weighted avg       0.80      0.76      0.76      1442\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Home\\scoop\\apps\\python\\current\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# LogReg\n",
    "vectorizer = CountVectorizer(stop_words=stops)\n",
    "\n",
    "X = vectorizer.fit_transform(train.comment)\n",
    "X_test = vectorizer.transform(test.comment)\n",
    "\n",
    "y = train.toxic.values\n",
    "y_test = test.toxic.values\n",
    "\n",
    "clf = LogisticRegression(C=0.1, penalty='elasticnet', class_weight='balanced', max_iter=100, solver='saga', l1_ratio = 0.5)\n",
    "clf.fit(X, y)\n",
    "preds = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "15af4e1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['тебе', 'нахуй', 'блядь', 'блять', 'пиздец'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_index = []\n",
    "\n",
    "for i in np.sort(clf.coef_[0])[::-1][:12]:\n",
    "  top_index.append(list(clf.coef_[0]).index(i))\n",
    "vectorizer.get_feature_names_out()[top_index][2:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.97      0.86       953\n",
      "         1.0       0.90      0.42      0.57       489\n",
      "\n",
      "    accuracy                           0.79      1442\n",
      "   macro avg       0.83      0.70      0.71      1442\n",
      "weighted avg       0.81      0.79      0.76      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=300, max_depth=500)\n",
    "clf.fit(X, y)\n",
    "preds = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, preds, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['хохлов', 'хохлы', 'тебе', 'нахуй', 'очень'], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_index = []\n",
    "\n",
    "for i in np.sort(clf.feature_importances_)[::-1][:20]:\n",
    "  top_index.append(list(clf.feature_importances_).index(i))\n",
    "vectorizer.get_feature_names_out()[top_index][:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
